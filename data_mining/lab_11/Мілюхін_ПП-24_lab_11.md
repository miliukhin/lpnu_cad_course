---
pdf-engine: xelatex
header-includes:
- \input{$UNI/.templates/settings/preamble.tex}
- \input{$UNI/.templates/settings/minted_settings.tex}
- \newcommand\Type{\Lab}
- \Work{datamining}
- \renewcommand\Variant{5}
- \newcommand\Date{23.\the\month.\the\year}
- \newcommand\Number{11}
- \newcommand\Topic{Класифікація методом опорних векторів.}
---

\input{$UNI/.templates/parts/header.tex}
Ознайомитися та отримати навички побудови моделей класифікації за допомогою Data
Mining GUI бібліотеки Weka. На практиці вивчити роботу методу опорних векторів, навчитися
інтерпретувати результати роботу класифікатора.

# Завдання

1. Для індивідуального завдання вирішіть задачу класифікації за допомогою
   методу опорних векторів (functions.SMO).
2. Змінюючи параметри налаштування алгоритму, спробуйте досягти найвищої якості
   навчання класифікатора.
3. Здійсніть класифікацію методом опорних векторів із датасетом використаним у
   WEKA у Excel за допомогою пакету Excel2SVM
   (https://www.bioinformatics.org/Excel2SVM/)
4. Порівняйте отримані результати від різних систем.
5. У звіті надайте результати роботи алгоритму, його налаштування, а також
   результати порівняння.

# Хід роботи
## Weka

\footnotesize

```r
=== Run information ===

Scheme:       weka.classifiers.functions.SMO -C 1.0 -L 0.001 -P 1.0E-12 -N 0 -V -1 -W 1 -K "weka.classifiers.functions.supportVector.PolyKernel -E 1.0 -C 250007" -calibrator "weka.classifiers.functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4"
Relation:     iris
Instances:    150
Attributes:   5
              sepallength
              sepalwidth
              petallength
              petalwidth
              class
Test mode:    split 80.0% train, remainder test

=== Classifier model (full training set) ===

SMO

Kernel used:
  Linear Kernel: K(x,y) = <x,y>

Classifier for classes: Iris-setosa, Iris-versicolor

BinarySMO

Machine linear: showing attribute weights, not support vectors.

         0.6829 * (normalized) sepallength
 +      -1.523  * (normalized) sepalwidth
 +       2.2034 * (normalized) petallength
 +       1.9272 * (normalized) petalwidth
 -       0.7091

Number of kernel evaluations: 352 (70.32% cached)

Classifier for classes: Iris-setosa, Iris-virginica

BinarySMO

Machine linear: showing attribute weights, not support vectors.

         0.5886 * (normalized) sepallength
 +      -0.5782 * (normalized) sepalwidth
 +       1.6429 * (normalized) petallength
 +       1.4777 * (normalized) petalwidth
 -       1.1668

Number of kernel evaluations: 284 (68.996% cached)

Classifier for classes: Iris-versicolor, Iris-virginica

BinarySMO

Machine linear: showing attribute weights, not support vectors.

         0.3176 * (normalized) sepallength
 +      -0.863  * (normalized) sepalwidth
 +       3.0543 * (normalized) petallength
 +       4.0815 * (normalized) petalwidth
 -       4.5924

Number of kernel evaluations: 453 (61.381% cached)



Time taken to build model: 0.02 seconds

=== Evaluation on test split ===

Time taken to test model on test split: 0 seconds

=== Summary ===

Correctly Classified Instances          29               96.6667 %
Incorrectly Classified Instances         1                3.3333 %
Kappa statistic                          0.9497
Mean absolute error                      0.2296
Root mean squared error                  0.2854
Relative absolute error                 51.6247 %
Root relative squared error             60.4978 %
Total Number of Instances               30

=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     Iris-setosa
                 1.000    0.050    0.909      1.000    0.952      0.929    0.975     0.909     Iris-versicolor
                 0.889    0.000    1.000      0.889    0.941      0.921    0.974     0.942     Iris-virginica
Weighted Avg.    0.967    0.017    0.970      0.967    0.966      0.953    0.984     0.952

=== Confusion Matrix ===

  a  b  c   <-- classified as
 11  0  0 |  a = Iris-setosa
  0 10  0 |  b = Iris-versicolor
  0  1  8 |  c = Iris-virginica
```

\normalsize

Вимкнувши нормалізацію, я досяг 100% точності класифікації

\footnotesize

```r
=== Run information ===

Scheme:       weka.classifiers.functions.SMO -C 1.0 -L 0.001 -P 1.0E-12 -N 2 -V -1 -W 1 -K "weka.classifiers.functions.supportVector.PolyKernel -E 1.0 -C 250007" -calibrator "weka.classifiers.functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4" -batch-size 10
Relation:     iris
Instances:    150
Attributes:   5
              sepallength
              sepalwidth
              petallength
              petalwidth
              class
Test mode:    split 80.0% train, remainder test

=== Classifier model (full training set) ===

SMO

Kernel used:
  Linear Kernel: K(x,y) = <x,y>

Classifier for classes: Iris-setosa, Iris-versicolor

BinarySMO

Machine linear: showing attribute weights, not support vectors.

         0.0459 * sepallength
 +      -0.5219 * sepalwidth
 +       1.0031 * petallength
 +       0.4641 * petalwidth
 -       1.4491

Number of kernel evaluations: 276 (75.135% cached)

Classifier for classes: Iris-setosa, Iris-virginica

BinarySMO

Machine linear: showing attribute weights, not support vectors.

         0.0095 * sepallength
 +      -0.1796 * sepalwidth
 +       0.5367 * petallength
 +       0.2946 * petalwidth
 -       1.5143

Number of kernel evaluations: 264 (61.404% cached)

Classifier for classes: Iris-versicolor, Iris-virginica

BinarySMO

Machine linear: showing attribute weights, not support vectors.

        -0.5962 * sepallength
 +      -0.972  * sepalwidth
 +       2.0313 * petallength
 +       2.008  * petalwidth
 -       6.786

Number of kernel evaluations: 512 (73.851% cached)



Time taken to build model: 0.02 seconds

=== Evaluation on test split ===

Time taken to test model on test split: 0 seconds

=== Summary ===

Correctly Classified Instances          30              100      %
Incorrectly Classified Instances         0                0      %
Kappa statistic                          1
Mean absolute error                      0.2222
Root mean squared error                  0.2722
Relative absolute error                 49.9594 %
Root relative squared error             57.6824 %
Total Number of Instances               30

=== Detailed Accuracy By Class ===

                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class
                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     Iris-setosa
                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     Iris-versicolor
                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     Iris-virginica
Weighted Avg.    1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000

=== Confusion Matrix ===

  a  b  c   <-- classified as
 11  0  0 |  a = Iris-setosa
  0 10  0 |  b = Iris-versicolor
  0  0  9 |  c = Iris-virginica
```

\normalsize

## R

\inputminted{r}{script.r}

\inputminted{r}{output}

# Висновок

Я ознайомився з методом опорних векторів у задачі класифікації та застосував його у Weka й R. В результаті у Weka я досяг 100% точності класифікації, а в R --- 96.67% (один неправильно класифікований екземпляр).

# Відповіді на контрольні запитання

1. **Що таке опорні векторні машини?**
   Опорні векторні машини (SVM) - це алгоритм машинного навчання, який
   використовується як для класифікації, так і для регресії. Вони шукають
   оптимальну гіперплощину в N-вимірному просторі, яка найкращим чином розділяє
   дані різних класів (у випадку класифікації) або найкращим чином апроксимує
   дані (у випадку регресії).

2. **Що таке опорні вектори в SVM?**
   Опорні вектори - це точки навчального набору даних, які лежать найближче до
   гіперплощини розділення. Вони визначають положення гіперплощини та
   використовуються для її побудови.

3. **Як працюють опорні векторні машини?**
   SVM працюють шляхом знаходження гіперплощини з
   максимальною відстанню між цією площиною та найближчими до неї точками
   навчального набору даних, які належать різним класам.

4. **Яка геометрична інтуїція стоїть за SVM?**
   Геометрична інтуїція за SVM полягає в тому, що вони шукають гіперплощину,
   яка максимально розділяє дані різних класів, тобто таку площину, на яку
   можна висунути паралельні площини, які не містять точок даних.

5. **Що вам відомо про Hard Margin SVM і Soft Margin SVM?**
   Hard Margin SVM намагається знайти гіперплощину з максимальною маржею без
   помилок класифікації, що може бути нестійким до викидів. Soft Margin SVM
   дозволяє деяку помилку класифікації для кращої загальної генералізації і
   більшої стійкості до викидів.

6. **Що таке трюк з ядром у SVM і чим він корисний?**
   Трюк з ядром у SVM - це метод, який дозволяє розширити лінійно роздільну
   гіперплощину на більш складні дані шляхом перетворення вихідного простору
   даних в більш високорозмірний простір. Це дозволяє ефективно розділяти дані,
   які не є лінійно роздільними в вихідному просторі.

7. **Що впливає на межі прийняття рішень у SVM?**
   Межі прийняття рішень у SVM визначаються положенням гіперплощини, яка
   розділяє дані різних класів, а також величиною та формою маржі, яка
   відокремлює класи.

8. **Яка різниця в ідеї використання опорної векторної машини для регресії та класифікації?**
   В ідеї використання опорної векторної машини для регресії та класифікації
   полягає в тому, що вони шукають оптимальну гіперплощину для розділення
   класів або апроксимації функції регресії, яка максимізує маржу або мінімізує
   помилку.

9. **Яка мінімально можлива кількість опорних векторів для N-вимірного набору** даних?**
   Мінімальна кількість опорних векторів для N-вимірного набору даних залежить
   від розподілу даних та складності простору. Зазвичай це може бути декілька
   векторів, але конкретне число може відрізнятися для різних наборів даних.

10. **Як мати справу з кількома класами за допомогою SVM?**
    Для роботи з кількома класами за допомогою SVM можна використовувати
	методи, такі як один проти всіх (one-vs-all) або один проти одного
	(one-vs-one), де модель навчається для розпізнавання кожного класу окремо.

11. **Порівняйте K-Nearest Neighbors (KNN) і SVM**
    Порівняння K-Nearest Neighbors (KNN) і SVM: KNN - це лінивий алгоритм, який
	використовує наближеність точок даних, тоді як SVM - це ефективний
	алгоритм, який шукає оптимальну гіперплощину для розділення класів.

12. **Коли SVM не є хорошим підходом?**
    SVM не є хорошим підходом, коли дані мають складну структуру та велику
	кількість шуму, коли кількість вимірів даних набагато перевищує кількість
	спостережень або коли дані мають складні взаємозв'язки.

13. **Чи дає SVM якийсь імовірнісний результат?** Ні.
